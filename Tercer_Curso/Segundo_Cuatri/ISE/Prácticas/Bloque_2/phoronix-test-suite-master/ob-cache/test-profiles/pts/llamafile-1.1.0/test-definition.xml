<?xml version="1.0"?>
<!--Phoronix Test Suite v10.8.4-->
<PhoronixTestSuite>
  <TestInformation>
    <Title>Llamafile</Title>
    <AppVersion>0.7</AppVersion>
    <Description>Mozilla's Llamafile allows distributing and running large language models (LLMs) as a single file. Llamafile aims to make open-source LLMs more accessible to developers and users. Llamafile supports a variety of models, CPUs and GPUs, and other options.</Description>
    <ResultScale>Tokens Per Second</ResultScale>
    <Proportion>HIB</Proportion>
    <TimesToRun>3</TimesToRun>
  </TestInformation>
  <TestProfile>
    <Version>1.1.0</Version>
    <SupportedPlatforms>Linux</SupportedPlatforms>
    <SoftwareType>Utility</SoftwareType>
    <TestType>System</TestType>
    <License>Free</License>
    <EnvironmentSize>40000</EnvironmentSize>
    <ProjectURL>https://llamafile.ai/</ProjectURL>
    <RepositoryURL>https://github.com/Mozilla-Ocho/llamafile</RepositoryURL>
    <Maintainer>Michael Larabel</Maintainer>
  </TestProfile>
  <TestSettings>
    <Option>
      <DisplayName>Test</DisplayName>
      <Identifier>test</Identifier>
      <Menu>
        <Entry>
          <Name>mistral-7b-instruct-v0.2.Q8_0</Name>
          <Value>run-mistral</Value>
        </Entry>
        <Entry>
          <Name>llava-v1.5-7b-q4</Name>
          <Value>run-llava</Value>
        </Entry>
        <Entry>
          <Name>wizardcoder-python-34b-v1.0.Q6_K</Name>
          <Value>run-wizardcoder</Value>
        </Entry>
      </Menu>
    </Option>
    <Option>
      <DisplayName>Acceleration</DisplayName>
      <Identifier>accel</Identifier>
      <Menu>
        <Entry>
          <Name>CPU</Name>
          <Value>--gpu DISABLE</Value>
        </Entry>
        <Entry>
          <Name>GPU AUTO</Name>
          <Value>--gpu AUTO</Value>
        </Entry>
      </Menu>
    </Option>
  </TestSettings>
</PhoronixTestSuite>
